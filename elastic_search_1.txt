AULA 1

A complexidade da busca

Procurar por registros em meio a grandes volumes de dados é uma tarefa complicada e 
há muitos anos recebe atenção de diversas áreas de pesquisa. Por décadas, bancos de 
dados relacionais foram os principais motores por trás de qualquer solução de busca.

Diversos bancos de dados oferecem a capacidade de busca cheia em texto (full-text search).
Habilitar este recurso necessita, em geral, de tarefas administrativas como instalação de 
add-ons, trocas de configurações do banco e execuções de procedures.

Seria ideal uma solução mais simples, flexível e portável, afinal de contas, não queremos 
contratar um DBA (Administrador de Banco de Dados) ou nos tornarmos especialistas em um 
banco de dados para poder fazer buscas que vão além do famoso e nada eficiente campo like %valor%.

Uma outra dificuldade em lidar com buscas está ligada à maneira com que a busca em si é orientada. 
Tanto em bancos de dados relacionais, quanto em bancos de dados não relacionais, conhecidos como NoSQL, 
buscas são orientadas a colunas ou atributos chaves que devem ser indexados previamente.

Não queremos também estar atrelados a campos específicos e exigir que nosso usuário precise saber detalhes 
do nosso sistema para poder extrair a informação que ele necessita. Por exemplo, imagine que queremos 
encontrar em uma tabela todas as vendas de computadores que ocorreram no estado de São Paulo na última semana. 
Para termos uma busca eficiente, precisamos que boa parte destes campos estejam previamente indexados, caso contrário 
a busca pode acabar varrendo a tabela toda.

Além disso, se liberamos esta busca para usuários de um sistema, somos praticamente obrigados a colocar um 
formulário de busca. Imagine o “sucesso” (sarcasmo) que o Google teria caso oferecesse um formulário de busca, em vez
de um campo livre de busca.

Engine de busca

Felizmente, existem bibliotecas que nos ajudam a ter bastante flexibilidade em nossas buscas. Um exemplo é o 
Apache Lucene, que é uma biblioteca em Java que oferece um motor de busca (search engine) poderoso.

Lucene é orientado a documentos e possui funcionalidades como busca exata, busca por similaridade, highlight do 
termo procurado no resultado, busca por termos em documento e busca por frase, além de também suportar analisadores 
de texto em diversos idiomas. Ainda que o Lucene seja excelente do ponto de vista de search engine, ele possui 
alguns aspectos que limitam sua adoção. Por exemplo, como o Lucene é escrito em Java, é difícil utilizá-lo diretamente 
com linguagens de programação como Ruby ou C#.

O Lucene foi desenhado para ser executado em uma única JVM. Isso nos limita tanto no volume de dados, afinal toda informação 
fica armazenada em um único nó, não temos tolerância a falhas e alta disponibilidade, afinal, caso este nó tenha problemas, 
nosso search-engine estaria indisponível.

Dados os volumes de dados e as necessidades de disponibilidade atuais, ter um sistema que depende de uma única máquina 
(seja virtual ou física) é de longe um grande problema. Estamos interessados no poder de busca oferecido pelo Lucene, 
porém em um ambiente na nuvem, com alta disponibilidade e escalabilidade horizontal, afinal queremos poder adicionar 
mais máquinas (baratas) quando for necessário.

ElasticSearch: Lucene e análise de dados na Nuvem

ElasticSearch é uma implementação de código aberto disponibilizada sob a licença Apache 2, suportada pela empresa Elastic.co que 
traz o poder do Lucene para o ambiente da nuvem. O ElasticSearch aborda os problemas descritos acima, tais como distribuição de 
dados e alta disponibilidade, tomando conta de detalhes como replicação de dados e tolerância a falhas de hardware. 
Com o aumento do poder de processamento que a nuvem nos dá, o ElasticSearch suporta também operações como agregações e buscas 
geo-espaciais que escalam horizontalmente ao nível de terabytes de dados.

Vale destacar que o ElasticSearch tem sido muito utilizado como ferramenta de análise de dados (data analytics), já que ele nos 
oferece a combinação de um poderoso full-text search engine com data analytics em larga escala. 
Como um exemplo real, imagine que queremos saber os 100 produtos mais vendidos no último ano e os seus valores médios de venda. 
Este problema é relativamente fácil de resolver em um banco de dados comum. Porém, queremos também limitar nossos resultados 
a produtos que tiveram bons comentários de clientes. Existem algumas frases (e não palavras) chaves com palavras que devemos 
utilizar na busca e nos ajuda a definir o que é um comentário positivo ou negativo.

A interação com o ElasticSearch, diferentemente da interação com o Lucene, acontece com o uso do formato JSON através de Restful APIs. 
Tal abordagem que nos permite ter um search engine em Java que interopera com diversas linguagens de programação. ElasticSearch oferece 
também como opção bibliotecas oficiais em diversas linguagens, como Javascript, Python, Java, Groovy, Perl, PHP, Ruby e .Net que abstraem 
os detalhes da interação via protocolo HTTP.


GET _search
{
  "query": {
    "match_all": {}
  }
}

POST catalogo/_doc/
{
    "nome": "João Silva",
    "interesses": ["futebol", "música", "literatura"],
    "cidade": "São Paulo",
    "formação": "Letras",
    "estado": "SP",
    "país": "Brasil"
}

GET catalogo/_count

POST catalogo/_doc/1
{
    "nome": "João Silva",
    "interesses": ["futebol", "música", "literatura"],
    "cidade": "São Paulo",
    "formação": "Letras",
    "estado": "SP",
    "país": "Brasil"
}

GET catalogo/_doc/1

GET catalogo/_search

GET catalogo/_search/?q=futebol

Você está trabalhando um banco de dados de filmes. Então você faz uma pesquisa usando o método GET com a função 
_search da API do Elasticsearch:

GET filmes/_search?q=harry+potter

O que produz o resultado em JSON:

{
  "took" : 1,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 4,
      "relation" : "eq"
    },
    "max_score" : 1.0,
    "hits" : [
      {
        "_index" : "filmes",
        "_type" : "_doc",
        "_id" : "A9TJcW8B_0egjg3g3TQs",
        "_score" : 1.0,
        "_source" : {
          "nome" : "Harry Potter e a Pedra Filosofal",
          "ano" : 2001
        }
      },
      {
        "_index" : "filmes",
        "_type" : "_doc",
        "_id" : "2",
        "_score" : 1.0,
        "_source" : {
          "nome" : "Harry Potter e a Câmara Secreta",
          "ano" : 2002
        }
      },
      {
        "_index" : "filmes",
        "_type" : "_doc",
        "_id" : "BNTJcW8B_0egjg3g5zTG",
        "_score" : 1.0,
        "_source" : {
          "nome" : "Harry Potter e o Prisioneiro de Azkaban",
          "ano" : 2004
        }
      },
      {
        "_index" : "filmes",
        "_type" : "_doc",
        "_id" : "4",
        "_score" : 1.0,
        "_source" : {
          "nome" : "Harry Potter e o Cálice de Fogo",
          "ano" : 2005
        }
      }
    ]
  }
}

Você quer investigar de que forma esses documentos foram inseridos no índice do Elasticsearch.

Qual sequência de comandos abaixo armazenou esses documentos no índice do Elasticsearch?

POST filmes/_doc
{ "nome": "Harry Potter e a Pedra Filosofal", "ano": 2001 }

POST filmes/_doc/2
{ "nome": "Harry Potter e a Câmara Secreta", "ano": 2002}

POST filmes/_doc
{ "nome": "Harry Potter e o Prisioneiro de Azkaban", "ano": 2004}

POST filmes/_doc/4
{ "nome": "Harry Potter e o Cálice de Fogo", "ano": 2005}

Correto. Os filmes "Harry Potter e a Pedra Filosofal" e "Harry Potter e o Prisioneiro de Azkaban"
foram inseridos com id implícito (atribuído automaticamente pelo Elasticsearch), enquanto os filmes 
"Harry Potter e a Câmara Secreta" e "Harry Potter e o Cálice de Fogo" foram inseridos com id específico.

ElasticSearch não é a única solução disponível que traz o Lucene para a nuvem. É natural que a própria 
Apache Foundation tenha sua própria solução, afinal, ela é a casa do Lucene.

A solução da Apache tem o nome de Apache Solr. Solr possui um abordagem semelhante que também foca em 
interoperabilidade e ainda suporta outros tipos de formatos como CSV e XML que não são suportados nativamente 
pelo ElasticSearch. Contudo, Solr não é muito flexível em relação a extensões e não possui tolerância a falhas 
nativamente, já que o suporte é dado via SolrCloud.

Aula 2

Banco Relacional    Elasticsearch
Instância           Index
Tabela              Type (default > v7: _doc)
Esquema             Mapping
Tupla               Document
Coluna              Attribute

Conjunto

Um cluster Elasticsearch é um grupo de uma ou mais instâncias de nó que estão conectadas. O poder de um cluster 
Elasticsearch está na distribuição de tarefas, pesquisa e indexação em todos os nós do cluster.

Node (Nó)
Um nó é um único servidor que faz parte de um cluster. Um nó armazena dados e participa dos recursos de 
indexação e pesquisa do cluster. Um nó Elasticsearch pode ser configurado de diferentes maneiras:

Node Master (nó mestre) – controla o cluster Elasticsearch e é responsável por todas as operações de todo o 
cluster, como criar / excluir um índice e adicionar / remover nós.

Data Node (nó de dados) – armazena dados e executa operações relacionadas a dados, como pesquisa e agregação.

Client Node (nó cliente) – encaminha solicitações de cluster para o nó mestre e solicitações relacionadas a 
dados para nós de dados.

Shards (Fragmentos)
Elasticsearch fornece a capacidade de subdividir o índice em várias partes chamadas shards. Cada fragmento é 
em si um “índice” totalmente funcional e independente que pode ser hospedado em qualquer nó de um cluster. 
Distribuindo os documentos em um índice em vários fragmentos e distribuindo esses fragmentos em vários nós, 
o Elasticsearch pode garantir redundância, o que protege contra falhas de hardware e aumenta a capacidade de 
consulta conforme os nós são adicionados a um cluster.

Réplicas
Elasticsearch permite que você faça uma ou mais cópias dos fragmentos de seu índice, que são chamados de 
“fragmentos de réplica” ou apenas “réplicas”. Basicamente, um shard de réplica é uma cópia de um shard primário. Cada documento em um índice pertence a um fragmento primário. As réplicas fornecem cópias redundantes de seus dados para proteger contra falhas de hardware e aumentar a capacidade de atender a solicitações de leitura, como pesquisa ou recuperação de um documento.
Fonte": https://www.infomach.com.br/o-que-e-elasticsearch-como-funciona-e-para-que-serve/

Outras fontes:

https://github.com/alefeans/elastic-stack/blob/master/pages/node_cluster.md
https://github.com/alefeans/elastic-stack/blob/master/pages/shards_replicas.md
https://techlipe.medium.com/elasticsearch-tudo-que-voc%C3%AA-precisa-saber-sobre-a-ferramenta-de-buscas-da-elastic-parte-5-73895e0e7e65

HEAD catalogo/_doc/1

HEAD catalogo/_doc/100

GET catalogo/_doc/100

PUT catalogo/_doc/50

PUT /catalogo/_doc/50
{
    "nome": "Marcelo Ricardo de Oliveira",
    "interesses": [
        "cinema",
        "música",
        "programação"
    ],
    "cidade": "São Paulo",
    "formação": "Tecnologia da Informação",
    "estado": "SP",
    "país": "Brasil"
}

GET catalogo/_doc/50

GET catalogo/_doc/1

DELETE catalogo/_doc/1

POST catalogo/_update/50
{
  "doc": {
    "nome": "Marcelo R. Oliveira"
  }
}

GET catalogo/_doc/50

Para atualizar, modificar o atributo nome do documento de id 1 para Douglas Quintanilha, que comando da API do 
Elasticsearch e qual URI devemos utilizar?

POST catalogo/_update/1
    {
        "doc": {
            "nome": "Douglas Quintanilha"
        }
    }

Correto. Para atualizar somente um ou mais atributos, devemos utilizar a sintaxe com o método POST e a função 
_update, passando os atributos, juntamente com os seus novos valores, dentro de um "doc".

Vale lembrar que uma vez que um documento é criado em uma instância do ElasticSearch, este documento torna-se 
imutável. No caso de uma atualização a um documento existente, por exemplo como fizemos com o método POST, 
uma nova versão do documento é criada. Se repararmos bem nas respostas recebidas, notaremos os atributos 
_created e _version. A resposta para a criação de um novo documento possui _created = true e _version = 1. 
A resposta para atualizações possui _created = false e _version será a versão anterior do documento acrescida 
de 1.

Para remover o documento de id 23, qual comando e URI devemos utilizar?

DELETE /catalogo/_doc/23

Correto. O comando que devemos utilizar é o método HTTP DELETE, que remove o documento, caso ele exista.
E a URI será composta pelo índice, pelo tipo “_doc” e pelo id que queremos excluir, no caso o 23.

Aula 3

GET catalogo/_search/?q=futebol

GET catalogo/_search/?q=estado:SP

GET catalogo/_search/?q=estado:futebol

GET catalogo/_search/?q=futebol&size=10&from=0

Buscando uma receita

Normalmente nos sites de receitas, buscamos por algo direto como Bolo de Fubá, Torta de frango ou Bolo de
Chocolate. Mas um problema comum quando encontramos uma receita, é que muitas vezes não possuímos todos
os ingredientes necessários, nos fazendo ter que ir ao mercado buscar os ingredientes faltosos.

Pensando nessa oportunidade, um desenvolvedor resolveu criar um website que faz uma busca reversa, na qual o 
usuário coloca os ingredientes que possui em casa e, na sequência, ele busca por receitas que contêm aqueles 
ingredientes. Nisso, ele viu uma oportunidade perfeita de usar o Elastic Search!

Veja como é o banco de receitas dele:

{
    "nome": "Bolo de Fubá",
    "descricao" : "Um delicioso bolo de fubá, com toque bem caseiro!",
    "ingredientes" ["farinha","manteiga","fermento","açucar","leite","fubá"]
}
{
    "nome": "Bolo de Chocolate",
    "descricao" : "Um delicioso bolo de chocolate, receita da vovó !",
    "ingredientes" ["farinha","manteiga","fermento","açucar","leite","chocolate"]
}
{
    "nome": "Torta de Frango",
    "descricao" : "Uma torta de frango incrível para o seu lanche com a família!",
    "ingredientes" ["farinha","manteiga","fermento","sal","leite","frango"]
}
...
// várias outras receitas

Se ele deseja retornar apenas as primeiras 30 receitas que tem como ingrediente o fermento , qual busca ele 
deve utilizar ?

_search?q=ingredientes:fermento&size=30

Correto! Sempre que realizamos uma busca, devemos utilizar a sintaxe campo:termo. Então, se queremos buscar 
pelo termo fermento no campo ingredientes, vamos usar ingredientes:fermento, mas como queremos limitar a 30 
resultados, utilizaremos o operador & para concatenar o size=30 ao resto da busca.

Paginando os resultados

Nosso desenvolvedor do último exercício notou que 30 resultados era um número muito alto para mostrar para seus 
usuários. Para isto, ele resolveu trocar a quantidade máxima para 10 resultados e, além disso, colocar uma 
paginação de receitas, de modo que as pessoas poderiam escolher se queriam começar vendo da receita de número 
1 até a 10ª, ou da 11ª até a 20ª e assim por diante.

Porém, apesar de sua boa intenção, ele não soube qual recurso do Elastic Serch ele poderia utilizar para tal 
feito.

Selecione a alternativa abaixo que auxilia o nosso amigo desenvolvedor a retornar as receitas que tem em seus 
ingredientes a farinha, mostrando de 10 em 10 , a partir do vigésimo primeiro resultado da lista de resultados.

_search?q=ingredientes:farinha&size=10&from=20

Correto! Para ajudar nosso amigo desenvolvedor, temos que utilizar o conhecimentos que já temos para selecionar 
os ingredientes que possuem farinha:

_search?q=ingredientes:farinha

Além disso, também precisamos limitar o tamanho dos resultados para 10, então vamos utilizar o operador & para 
adicionar um novo limitador a busca:

_search?q=ingredientes:farinha&size=10

E precisamos que a nossa exibição comece a partir do vigésimo resultado, e para isto vamos utilizar o termo 
from=20 a nossa busca , concatenando com o operado &:

_search?q=ingredientes:farinha&size=10&from=20

Assim, nossa busca irá retornar todas as receitas que tem farinha nos ingredientes, mostrando em lotes de 10 
resultados, a partir do vigésimo!

API Scroll

Quando utilizamos paginação simples, temos que tomar cuidado para não causarmos instabilidade no cluster. 
Caso solicitemos 10.000 registros, todas as shards participantes na consulta podem retornar esta quantidade.

Por exemplo, caso tenhamos 3 shards com 100.000 documentos em cada e pedimos os primeiros 10.000 resultados, 
o nó coordenador terá de processar 30.000 documentos, executar a ordenação e pegar os primeiros 10.000.

Para detalhes, acesse o link a seguir:

https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-scroll.html

*Não recomendamos mais o uso da API de rolagem para paginação profunda. Se você precisar preservar o estado do 
índice ao paginar mais de 10.000 ocorrências, use o search_afterparâmetro com um ponto no tempo (PIT).*

https://www.elastic.co/guide/en/elasticsearch/reference/current/paginate-search-results.html#scroll-search-results
